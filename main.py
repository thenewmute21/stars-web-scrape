from fastapi import FastAPI, BackgroundTasks
from pydantic import BaseModel, EmailStr
import uvicorn
import requests
import concurrent.futures
import logging
import asyncio
from scrape import run_scrape

# Logging setup ‚Äî write to file and terminal
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    handlers=[
        logging.FileHandler("/root/stars-web-scrape/log.txt"),
        logging.StreamHandler()
    ]
)

app = FastAPI()
resonse_webhook_url = "https://hook.integrator.boost.space/k80rinp9fgzwhlysiohlvy12x8r0qa36"

# Limit to 2 concurrent scrapes globally
semaphore = asyncio.Semaphore(2)

class UserCredential(BaseModel):
    email: EmailStr
    password: str
    url: str
    FUB_ID: int
    FUB_email: EmailStr

@app.post("/")
async def main(user_credential: UserCredential, background_tasks: BackgroundTasks):
    logging.info(f"üì¨ Received POST request for {user_credential.FUB_email} (FUB_ID: {user_credential.FUB_ID})")
    background_tasks.add_task(
        run_scrape_and_send_webhook,
        user_credential.email,
        user_credential.password,
        user_credential.url,
        user_credential.FUB_ID,
        user_credential.FUB_email
    )
    return {'message': f'Scraping in progress. Check webhook for results. üëâ {resonse_webhook_url}'}

@app.get("/health")
async def health():
    return {"status": "ok"}

async def run_scrape_and_send_webhook(email: EmailStr, password: str, url: str, FUB_ID: int, FUB_email: EmailStr):
    try:
        async with semaphore:
            logging.info(f"üî• Started scraping script for {FUB_email} ‚Äî URL: {url}")

            loop = asyncio.get_event_loop()
            copied_text = await loop.run_in_executor(None, run_scrape, email, password, url)

            logging.info(f"‚úÖ Scrape completed for {FUB_email}, sending webhook...")

            send_webhook({
                "copied_text": copied_text,
                "FUB_ID": FUB_ID,
                "FUB_email": FUB_email
            })

    except concurrent.futures.TimeoutError:
        logging.error(f"‚è± Scraping timed out for {FUB_email}")
    except Exception as error:
        logging.error(f"‚ùå Scraping failed for {FUB_email}: {type(error).__name__} ‚Äì {error}")

def send_webhook(response):
    logging.info("üì§ Sending webhook response...")
    logging.info(response)
    try:
        res = requests.post(resonse_webhook_url, json=response, timeout=10)
        if res.ok:
            logging.info("‚úÖ Webhook was successful")
        else:
            logging.warning("‚ö†Ô∏è Webhook failed. Retrying once...")
            res_retry = requests.post(resonse_webhook_url, json=response, timeout=10)
            if res_retry.ok:
                logging.info("‚úÖ Retry succeeded")
            else:
                logging.error(f"‚ùå Retry also failed. Status: {res_retry.status_code}")
                logging.error(res_retry.text)
    except requests.exceptions.RequestException as e:
        logging.error(f"‚ùå Webhook exception: {e}")

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000)
